# Project Structure

```
arg-surveillance-framework/
â”‚
â”œâ”€â”€ app/                                    # Main application package
â”‚   â”œâ”€â”€ __init__.py                        # Package initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                            # Agent execution modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ a1_sampling.py                 # A1: Sampling Design Agent
â”‚   â”‚   â”‚   â””â”€â”€ run_sampling_agent()       #   - Generates sampling strategy
â”‚   â”‚   â”‚   â””â”€â”€ validate_sampling_output() #   - Validates output structure
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a2_wetlab.py                   # A2: Wet-Lab Protocol Agent
â”‚   â”‚   â”‚   â””â”€â”€ run_wetlab_agent()         #   - Generates protocols
â”‚   â”‚   â”‚   â””â”€â”€ validate_wetlab_output()   #   - Checks guardrails
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a3_bioinfo.py                  # A3: Bioinformatics Pipeline Agent
â”‚   â”‚   â”‚   â””â”€â”€ run_bioinfo_agent()        #   - Generates bash/YAML
â”‚   â”‚   â”‚   â””â”€â”€ validate_bioinfo_output()  #   - Checks for execution commands
â”‚   â”‚   â”‚   â””â”€â”€ extract_bioinfo_sections() #   - Parses code blocks
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ a4_analysis.py                 # A4: Statistical Analysis Agent
â”‚   â”‚       â””â”€â”€ run_analysis_agent()       #   - Generates R workflows
â”‚   â”‚       â””â”€â”€ validate_analysis_output() #   - Checks for system calls
â”‚   â”‚       â””â”€â”€ extract_analysis_sections()#   - Parses R code
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                           # Prompt storage (8 files)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a1_sampling_system_prompt.py   # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â”œâ”€â”€ a1_sampling_user_prompt.py     # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a2_wetlab_system_prompt.py     # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â”œâ”€â”€ a2_wetlab_user_prompt.py       # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a3_bioinfo_system_prompt.py    # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â”œâ”€â”€ a3_bioinfo_user_prompt.py      # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ a4_analysis_system_prompt.py   # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚   â””â”€â”€ a4_analysis_user_prompt.py     # â† PASTE YOUR PROMPTS HERE
â”‚   â”‚
â”‚   â”œâ”€â”€ graph.py                           # LangGraph orchestration
â”‚   â”‚   â””â”€â”€ WorkflowState                  #   - State schema
â”‚   â”‚   â””â”€â”€ node_a1_sampling()             #   - A1 graph node
â”‚   â”‚   â””â”€â”€ node_a2_wetlab()               #   - A2 graph node
â”‚   â”‚   â””â”€â”€ node_a3_bioinfo()              #   - A3 graph node
â”‚   â”‚   â””â”€â”€ node_a4_analysis()             #   - A4 graph node
â”‚   â”‚   â””â”€â”€ create_workflow_graph()        #   - Build LangGraph
â”‚   â”‚   â””â”€â”€ run_workflow()                 #   - Main execution
â”‚   â”‚
â”‚   â”œâ”€â”€ llm.py                             # OpenAI API interface
â”‚   â”‚   â””â”€â”€ call_llm()                     #   - Single LLM call
â”‚   â”‚   â””â”€â”€ call_llm_with_history()        #   - Multi-turn conversation
â”‚   â”‚   â””â”€â”€ estimate_tokens()              #   - Token estimation
â”‚   â”‚
â”‚   â”œâ”€â”€ guards.py                          # Guardrail validators
â”‚   â”‚   â””â”€â”€ check_wetlab_guardrails()      #   - Detect actionable instructions
â”‚   â”‚   â””â”€â”€ check_bioinfo_guardrails()     #   - Detect execution commands
â”‚   â”‚   â””â”€â”€ check_analysis_guardrails()    #   - Detect system calls
â”‚   â”‚   â””â”€â”€ sanitize_output()              #   - Add warnings to output
â”‚   â”‚
â”‚   â”œâ”€â”€ cli.py                             # Command-line interface
â”‚   â”‚   â””â”€â”€ save_results()                 #   - Save to timestamped directory
â”‚   â”‚   â””â”€â”€ main()                         #   - CLI entry point
â”‚   â”‚
â”‚   â””â”€â”€ api.py                             # FastAPI REST API
â”‚       â””â”€â”€ /workflow/run                  #   - Sync workflow execution
â”‚       â””â”€â”€ /workflow/run-async            #   - Async workflow execution
â”‚       â””â”€â”€ /workflow/status/{run_id}      #   - Check workflow status
â”‚       â””â”€â”€ /workflow/output/{run_id}      #   - Get full output
â”‚       â””â”€â”€ /agent/{run_id}/{agent}        #   - Get specific agent output
â”‚
â”œâ”€â”€ runs/                                  # Workflow outputs (gitignored)
â”‚   â””â”€â”€ 20250109_143025/                   # Timestamped run directory
â”‚       â”œâ”€â”€ A1.md                          #   - A1 Markdown output
â”‚       â”œâ”€â”€ A1.json                        #   - A1 JSON output
â”‚       â”œâ”€â”€ A2.md                          #   - A2 Markdown output
â”‚       â”œâ”€â”€ A2.json                        #   - A2 JSON output
â”‚       â”œâ”€â”€ A2_guardrails.json             #   - A2 violations (if any)
â”‚       â”œâ”€â”€ A3.md                          #   - A3 Markdown output
â”‚       â”œâ”€â”€ A3.json                        #   - A3 JSON output
â”‚       â”œâ”€â”€ A3_guardrails.json             #   - A3 violations (if any)
â”‚       â”œâ”€â”€ A4.md                          #   - A4 Markdown output
â”‚       â”œâ”€â”€ A4.json                        #   - A4 JSON output
â”‚       â”œâ”€â”€ A4_guardrails.json             #   - A4 violations (if any)
â”‚       â”œâ”€â”€ validation_reports.json        #   - All validation results
â”‚       â”œâ”€â”€ full_state.json                #   - Complete workflow state
â”‚       â””â”€â”€ SUMMARY.md                     #   - Human-readable summary
â”‚
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ .env.example                           # Environment variable template
â”œâ”€â”€ .gitignore                             # Git ignore rules
â”‚
â”œâ”€â”€ README.md                              # Full documentation
â”œâ”€â”€ QUICK_START.md                         # Quick start guide
â”œâ”€â”€ STRUCTURE.md                           # This file
â”‚
â”œâ”€â”€ setup.sh                               # Setup script (Linux/Mac)
â”œâ”€â”€ run_example.py                         # Example workflow script
â””â”€â”€ example_query.txt                      # Example research question
```

## Key Files to Modify

### ğŸ”´ **MUST EDIT** (Before First Run)

1. **Prompts** (`app/prompts/*_prompt.py`): Replace all 8 placeholder prompts with your actual prompts from Markdown files

2. **Environment** (`.env`): Add your `OPENAI_API_KEY`

### ğŸŸ¡ **OPTIONAL** (Customize Behavior)

3. **Agents** (`app/agents/*.py`): Adjust validation logic, parsing, temperature, max_tokens

4. **Guardrails** (`app/guards.py`): Add/remove guardrail patterns, adjust risk thresholds

5. **Graph** (`app/graph.py`): Add new agents, change flow, add conditional routing

6. **LLM** (`app/llm.py`): Change model, adjust defaults, add retry logic

## Data Flow

```
User Query
    â†“
graph.py (LangGraph)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  node_a1_sampling()                             â”‚
â”‚    â†’ a1_sampling.py                             â”‚
â”‚    â†’ prompts/a1_*_prompt.py                     â”‚
â”‚    â†’ llm.py (OpenAI call)                       â”‚
â”‚    â†’ validate_sampling_output()                 â”‚
â”‚    â†’ state["a1_output"] = {...}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  node_a2_wetlab()                               â”‚
â”‚    â†’ a2_wetlab.py                               â”‚
â”‚    â†’ prompts/a2_*_prompt.py                     â”‚
â”‚    â†’ llm.py (OpenAI call)                       â”‚
â”‚    â†’ guards.py (check_wetlab_guardrails)        â”‚
â”‚    â†’ validate_wetlab_output()                   â”‚
â”‚    â†’ state["a2_output"] = {...}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  node_a3_bioinfo()                              â”‚
â”‚    â†’ a3_bioinfo.py                              â”‚
â”‚    â†’ prompts/a3_*_prompt.py                     â”‚
â”‚    â†’ llm.py (OpenAI call)                       â”‚
â”‚    â†’ guards.py (check_bioinfo_guardrails)       â”‚
â”‚    â†’ extract_bioinfo_sections()                 â”‚
â”‚    â†’ validate_bioinfo_output()                  â”‚
â”‚    â†’ state["a3_output"] = {...}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  node_a4_analysis()                             â”‚
â”‚    â†’ a4_analysis.py                             â”‚
â”‚    â†’ prompts/a4_*_prompt.py                     â”‚
â”‚    â†’ llm.py (OpenAI call)                       â”‚
â”‚    â†’ guards.py (check_analysis_guardrails)      â”‚
â”‚    â†’ extract_analysis_sections()                â”‚
â”‚    â†’ validate_analysis_output()                 â”‚
â”‚    â†’ state["a4_output"] = {...}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final State â†’ cli.py or api.py
    â†“
save_results() â†’ runs/<timestamp>/
```

## Import Chain

```python
# CLI/API imports graph
from app.graph import run_workflow

# graph imports agents
from app.agents.a1_sampling import run_sampling_agent
from app.agents.a2_wetlab import run_wetlab_agent
from app.agents.a3_bioinfo import run_bioinfo_agent
from app.agents.a4_analysis import run_analysis_agent

# agents import prompts
from app.prompts.a1_sampling_system_prompt import TEXT as SYSTEM_PROMPT
from app.prompts.a1_sampling_user_prompt import TEXT as USER_PROMPT

# agents import llm and guards
from app.llm import call_llm
from app.guards import check_wetlab_guardrails
```

## Module Responsibilities

| Module | Responsibility | Dependencies |
|--------|----------------|--------------|
| `prompts/*.py` | Store prompt text | None |
| `llm.py` | OpenAI API calls | `openai` |
| `guards.py` | Validate outputs | `re` |
| `agents/*.py` | Run agents, parse outputs | `prompts`, `llm`, `guards` |
| `graph.py` | Orchestrate workflow | `langgraph`, `agents` |
| `cli.py` | CLI interface | `graph` |
| `api.py` | REST API interface | `fastapi`, `graph` |

## Extension Points

1. **Add a new agent**: Create `app/agents/a5_myagent.py`, add prompts, register in `graph.py`

2. **Add guardrails**: Add pattern checks in `app/guards.py`

3. **Change LLM provider**: Replace `app/llm.py` with Anthropic, Google, etc.

4. **Add database**: Replace in-memory `workflow_runs` dict in `api.py` with PostgreSQL, Redis, etc.

5. **Add authentication**: Add FastAPI dependencies in `api.py`

6. **Add caching**: Wrap `call_llm()` with LangChain caching

7. **Add human-in-the-loop**: Add approval nodes in `graph.py`

