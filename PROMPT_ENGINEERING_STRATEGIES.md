# Complete Guide to Prompt Engineering Strategies
## All Novel Techniques Used in Your Multi-Agent Framework

---

## ðŸŽ¯ **Overview**

Your framework uses **10 innovative prompt engineering strategies** that work together to create expert-level AI reasoning. This document explains each one with examples.

---

## ðŸ“‹ **Table of Strategies**

| # | Strategy | What It Does | Where Used |
|---|----------|--------------|------------|
| 1 | **Two-Prompt System** | Separates identity from task | All agents |
| 2 | **Structured Reasoning Frameworks** | Step-by-step thinking process | All agents |
| 3 | **Decision Trees** | IF-THEN logic for choices | A2, A3, A4 |
| 4 | **Few-Shot Learning** | Examples to guide output | All agents |
| 5 | **Chain-of-Thought** | Forces step-by-step reasoning | All agents |
| 6 | **Output Templating** | Exact JSON/YAML schemas | All agents |
| 7 | **Adaptive Logic** | Handles missing information | A1, A2 |
| 8 | **Constraint Enforcement** | Explicit DO/DON'T rules | All agents |
| 9 | **Inter-Agent Communication** | Structured handoffs | All agents |
| 10 | **Guardrails** | Automated output validation | A2, A3, A4 |

---

## 1ï¸âƒ£ **Two-Prompt System**

### **What It Is:**
Each agent has TWO separate prompts:
- **System Prompt:** "Who am I?" (role, identity, expertise)
- **User Prompt:** "What do I do?" (specific task, input, output format)

### **Why It's Novel:**
Most AI systems use one large prompt. Separating identity from task makes it:
- âœ… Easier to maintain (update one without affecting the other)
- âœ… More flexible (same agent, different tasks)
- âœ… Clearer reasoning (agent knows its role)

### **Example from A1 Sampling Agent:**

**System Prompt (Identity):**
```
You are an expert sampling strategist for environmental microbiology 
and antibiotic resistance surveillance studies.

Your core reasoning framework:
1. Hypothesis Formulation
2. Design Selection
3. Sample Size Estimation
...

Your constraints:
- Output must be valid JSON
- Must justify sample sizes statistically
- Must provide testable hypotheses
```

**User Prompt (Task):**
```
Based on the user's research question, generate a complete sampling design.

User Query: ###USER_QUERY###

Return a JSON with the following sections:
- hypotheses
- sampling_design
- metadata_requirements
...
```

### **How They Work Together:**
```
System Prompt = Agent's brain (how to think)
      +
User Prompt = Agent's assignment (what to think about)
      â†“
Complete, structured output
```

---

## 2ï¸âƒ£ **Structured Reasoning Frameworks**

### **What It Is:**
A step-by-step process embedded in the System Prompt that guides the agent's thinking.

### **Why It's Novel:**
Instead of "figure it out," the AI follows a specific cognitive pathwayâ€”like a checklist that experts use.

### **Example: A1's 7-Step Framework**

```
Step 1: Hypothesis Formulation
  â†’ Convert question to Hâ‚€ and Hâ‚

Step 2: Design Selection
  â†’ Choose spatial/temporal/comparative

Step 3: Sample Size Estimation
  â†’ Calculate n for 80% power

Step 4: Metadata Prioritization
  â†’ List MUST/SHOULD/NICE-to-have

Step 5: Quality Control Strategy
  â†’ Specify controls and replication

Step 6: Constraint Assessment
  â†’ Identify limits and solutions

Step 7: Handoff Preparation
  â†’ Prepare info for next agent
```

### **Other Frameworks in Your System:**

**A2 (Wet-Lab):** 5-phase framework
```
1. Input Validation â†’ Check A1 output complete
2. Method Selection â†’ Use decision trees
3. Protocol Assembly â†’ Combine methods
4. QC Definition â†’ Specify controls
5. Handoff Preparation â†’ Pass to A3
```

**A3 (Bioinformatics):** 6-stage pipeline framework
```
1. Input Validation â†’ Check A2 output
2. QC Design â†’ FastQC, Trimmomatic
3. Assembly Strategy â†’ Choose assembler
4. Annotation Pipeline â†’ ARG databases
5. Normalization â†’ TPM/RPKM/DESeq2
6. Data Handoff â†’ Create YAML for A4
```

**A4 (Statistical Analysis):** 5-step workflow
```
1. Data Loading â†’ Parse data_handoff.yaml
2. Assumption Checking â†’ Shapiro-Wilk, Levene
3. Test Selection â†’ Parametric vs. non-parametric
4. Visualization â†’ PCoA, heatmaps
5. Interpretation â†’ Report generation
```

### **Why This Works:**
- âœ… Ensures completeness (no skipped steps)
- âœ… Mimics expert thinking
- âœ… Provides audit trail
- âœ… Makes debugging easier

---

## 3ï¸âƒ£ **Decision Trees**

### **What It Is:**
IF-THEN-ELSE logic embedded in prompts as flowcharts for method selection.

### **Why It's Novel:**
Decision trees are usually code (after AI output). Here, they're **inside** the prompt, guiding AI reasoning directly.

### **Example 1: A2 DNA Extraction Kit Selection**

```
Sample Matrix?
â”œâ”€ Soil/Sludge
â”‚   â”œâ”€ High biomass â†’ DNeasy PowerSoil Kit (Qiagen 12888-100)
â”‚   â””â”€ Low biomass â†’ ZymoBIOMICS DNA Miniprep Kit (Zymo D4300)
â”‚
â”œâ”€ Water
â”‚   â”œâ”€ After filtration â†’ DNeasy PowerWater Kit (Qiagen 14900-50-NF)
â”‚   â””â”€ Direct extraction â†’ Qiagen Blood & Tissue (if >10â¶ cells/mL)
â”‚
â”œâ”€ Activated sludge/biofilm
â”‚   â””â”€ FastDNA Spin Kit for Soil (MP Biomedicals 116560-200)
â”‚
â””â”€ Pure culture isolates
    â””â”€ DNeasy Blood & Tissue Kit (Qiagen 69506)
```

**AI follows this tree:**
```
Input: sample=water, biomass=high, method=filtration
  â†“
Tree path: Water â†’ After filtration â†’ PowerWater Kit
  â†“
Output: "DNeasy PowerWater Kit (14900-50-NF)"
```

### **Example 2: A3 Assembler Selection**

```
Read Length?
â”œâ”€ Short (PE75-100)
â”‚   â””â”€ Complexity?
â”‚       â”œâ”€ High â†’ MEGAHIT (fast)
â”‚       â””â”€ Low â†’ MEGAHIT (sufficient)
â”‚
â””â”€ Long (PE150-250)
    â””â”€ Complexity?
        â”œâ”€ High â†’ metaSPAdes (better quality)
        â””â”€ Low â†’ MEGAHIT (faster, good enough)
```

### **Example 3: A4 Statistical Test Selection**

```
Are data normally distributed?
â”œâ”€ YES (parametric)
â”‚   â””â”€ How many groups?
â”‚       â”œâ”€ 2 groups â†’ t-test
â”‚       â””â”€ 3+ groups â†’ ANOVA
â”‚
â””â”€ NO (non-parametric)
    â””â”€ How many groups?
        â”œâ”€ 2 groups â†’ Mann-Whitney U test
        â””â”€ 3+ groups â†’ Kruskal-Wallis test
```

### **Benefits:**
- âœ… Transparent reasoning (can see why AI chose X)
- âœ… Reproducible (same path every time)
- âœ… Evidence-based (trees built from literature)
- âœ… Easy to update (just edit the tree)

---

## 4ï¸âƒ£ **Few-Shot Learning**

### **What It Is:**
Providing 2-3 detailed examples in the prompt to show the AI what good output looks like.

### **Why It's Novel:**
Not just "here's an example"â€”these are COMPLETE, publication-quality examples that set a high bar.

### **Example from A1 Sampling Agent:**

**Few-Shot Example 1: Hospital Wastewater Study**
```json
{
  "study_metadata": {
    "research_question": "Does hospital wastewater contain higher ARG diversity?",
    "primary_objective": "Detection & Quantification",
    "study_system": "Hospital wastewater",
    "framework": "STROBE-metagenomics"
  },
  "hypotheses": {
    "primary": "Hospital wastewater harbors higher ARG diversity than municipal",
    "statistical_framework": "PERMANOVA (Î±=0.05) + Dunn's test (BH correction)"
  },
  "sampling_design": {
    "spatial_design": "3 hospital + 3 municipal WWTPs (paired by location)",
    "temporal_design": "Monthly for 6 months (capture seasonal variation)",
    "replication": {
      "biological_replicates": 5,
      "rationale": "n=5 provides 80% power to detect Cohen's d=0.5"
    }
  },
  "metadata_requirements": {
    "critical": ["site_ID", "date", "temp", "pH", "patient_census"],
    "supplementary": ["antibiotic_usage", "weather"],
    "optional": ["antibiotic_concentrations"]
  },
  "qc_strategy": {
    "negative_controls": "3 extraction blanks per batch",
    "positive_controls": "ZymoBIOMICS mock community (D6300)",
    "field_blanks": "Sterile water processed identically"
  },
  "handoff_to_wetlab": {
    "sample_type": "liquid wastewater",
    "biosafety_level": "BSL-2",
    "expected_biomass": "high",
    "target_molecule": "DNA",
    "downstream_analysis": "Shotgun metagenomics â†’ ARG annotation"
  }
}
```

**Few-Shot Example 2: Agricultural Runoff Study**
```json
{
  "study_metadata": {
    "research_question": "What is ARG transport from farm to river?",
    "primary_objective": "Source tracking",
    "study_system": "Agricultural runoff",
    "framework": "Spatial gradient sampling"
  },
  "sampling_design": {
    "spatial_design": "Upstream control â†’ Farm soil â†’ Runoff â†’ River downstream",
    "temporal_design": "After rainfall events (n=10 events)",
    "gradient_sampling": "0m, 50m, 100m, 500m, 1km from farm"
  },
  "statistical_power": "n=5 per location provides d=0.5 detection"
}
```

### **Why Few-Shot Works:**
- âœ… Shows complete structure (all required fields)
- âœ… Demonstrates quality level (detailed, justified)
- âœ… Provides domain language (proper terminology)
- âœ… Sets output format (JSON structure)

---

## 5ï¸âƒ£ **Chain-of-Thought Reasoning**

### **What It Is:**
Forcing the AI to show its work step-by-step, not just jump to conclusions.

### **Why It's Novel:**
Combined with structured frameworks, this creates transparent, auditable reasoning.

### **Example from A1 User Prompt:**

```
## Step 1: Parse User Query

Extract the following information:
- Study system (hospital, farm, natural environment)
- ARG context (surveillance, intervention, source tracking)
- Temporal scope (snapshot, time-series, longitudinal)
- Scale (local, regional, global)

## Step 2: Formulate Hypotheses

Based on Step 1, generate:
- Primary hypothesis (testable, specific)
- Secondary hypotheses (2-3 related questions)
- Statistical framework (PERMANOVA, DESeq2, etc.)

## Step 3: Design Spatial Sampling

Based on hypotheses from Step 2:
- If comparing groups â†’ Comparative design
- If tracking change â†’ Gradient design
- If monitoring â†’ Time-series design

## Step 4: Design Temporal Sampling
...
```

**AI must follow each step:**
```
Step 1 output â†’ Used in Step 2
Step 2 output â†’ Used in Step 3
Step 3 output â†’ Used in Step 4
...
```

### **Example Output (Chain-of-Thought):**

```
Step 1 Analysis:
- Study system: Hospital wastewater âœ“
- ARG context: Surveillance âœ“
- Temporal scope: 6 months (time-series) âœ“
- Scale: Local (single city) âœ“

Step 2 Reasoning:
Based on "hospital wastewater surveillance":
- Primary Hâ‚: Hospital has higher ARG diversity than municipal
- Statistical framework: PERMANOVA (for diversity comparison)

Step 3 Design Selection:
Based on Hâ‚ (comparison between two groups):
- Design type: Comparative (hospital vs. municipal)
- Plus Temporal (6 months for robustness)
â†’ Hybrid: Comparative + Temporal

Step 4 Sample Size:
For PERMANOVA with medium effect (d=0.5):
- Minimum: n=3 per group
- Recommended: n=5 per group (80% power)
â†’ 3 hospital + 3 municipal Ã— 5 reps = 30 samples/month
```

### **Benefits:**
- âœ… Transparent reasoning
- âœ… Can debug where AI went wrong
- âœ… Shows logic flow
- âœ… Builds trust in outputs

---

## 6ï¸âƒ£ **Output Templating**

### **What It Is:**
Providing exact JSON/YAML/R schemas in prompts so AI knows the precise output format.

### **Why It's Novel:**
Not just "output JSON"â€”provides complete, validated schemas with all required fields.

### **Example 1: A1 JSON Template**

```json
{
  "study_metadata": {
    "research_question": "[string]",
    "primary_objective": "[Detection|Quantification|Source tracking|Intervention]",
    "study_system": "[hospital|farm|natural|other]",
    "framework": "[STROBE-metagenomics|other]"
  },
  "hypotheses": {
    "primary": "[string: specific, testable hypothesis]",
    "secondary": ["[hypothesis 1]", "[hypothesis 2]"],
    "statistical_framework": "[PERMANOVA|DESeq2|other]"
  },
  "sampling_design": {
    "spatial_design": "[description]",
    "temporal_design": "[description]",
    "replication": {
      "biological_replicates": "[number]",
      "technical_replicates": "[number]",
      "rationale": "[statistical justification]"
    }
  },
  "metadata_requirements": {
    "critical": ["[variable 1]", "[variable 2]"],
    "supplementary": ["[variable 3]"],
    "optional": ["[variable 4]"]
  },
  "qc_strategy": {
    "negative_controls": "[description]",
    "positive_controls": "[description]",
    "field_blanks": "[description]"
  },
  "constraints": {
    "budget": "[amount or constraint]",
    "access": "[limitations]",
    "timeline": "[duration]",
    "solutions": ["[solution 1]", "[solution 2]"]
  },
  "handoff_to_wetlab": {
    "sample_type": "[liquid|solid|other]",
    "biosafety_level": "[BSL-1|BSL-2|BSL-3]",
    "expected_biomass": "[high|medium|low]",
    "target_molecule": "[DNA|RNA|both]",
    "sequencing_type": "[shotgun|amplicon]",
    "downstream_analysis": "[description]"
  }
}
```

### **Example 2: A3 YAML Template (data_handoff.yaml)**

```yaml
# Data Handoff from Bioinformatics to Statistical Analysis
input_files:
  arg_abundance:
    path: "results/arg_abundance_matrix.tsv"
    description: "ARG gene counts per sample"
  taxonomy:
    path: "results/taxonomy_matrix.tsv"
    description: "Taxonomic abundance per sample"
  metadata:
    path: "metadata/sample_metadata.csv"
    description: "Sample metadata and covariates"

format:
  arg_abundance:
    file_type: "TSV"
    rows: "samples (row names)"
    cols: "ARG genes (column names)"
    values: "Normalized counts (TPM)"
    normalization: "TPM (Transcripts Per Million)"
  
  taxonomy:
    file_type: "TSV"
    rows: "samples"
    cols: "taxa (genus level)"
    values: "Relative abundance (0-1)"

metadata_schema:
  required_columns:
    - sample_id
    - site_type
    - collection_date
    - replicate_id
  optional_columns:
    - temperature
    - pH
    - antibiotic_usage

quality_metrics:
  total_reads_per_sample: "Mean 8.5M Â± 1.2M"
  assembly_n50: "Mean 1.2 kb"
  arg_detection_rate: "95% of samples have â‰¥10 ARG genes"

analysis_recommendations:
  diversity: "Shannon, Simpson indices (vegan::diversity)"
  ordination: "PCoA with Bray-Curtis (phyloseq::ordinate)"
  differential_abundance: "DESeq2 or ALDEx2"
  group_comparisons: "PERMANOVA (vegan::adonis2)"
```

### **Benefits:**
- âœ… Consistent output format
- âœ… Automatic validation (can parse JSON)
- âœ… Machine-readable
- âœ… Easy to test

---

## 7ï¸âƒ£ **Adaptive Logic**

### **What It Is:**
Handling incomplete or ambiguous user inputs gracefully by providing alternatives.

### **Why It's Novel:**
Instead of failing or guessing, the AI generates multiple scenarios and lets the user choose.

### **Example from A1:**

```
## Adaptive Logic: Alternative Scenarios

If critical information is missing from user query, provide 2-3 alternative scenarios:

**Example:** User doesn't specify if cultivation is needed

Alternative Scenarios:
{
  "scenario_1": {
    "assumption": "Cultivation NOT required (culture-independent only)",
    "sampling_modifications": {
      "preservation": "Freeze at -80Â°C immediately",
      "sample_type": "Whole sample for DNA extraction"
    }
  },
  "scenario_2": {
    "assumption": "Cultivation IS required (isolate recovery)",
    "sampling_modifications": {
      "preservation": "Keep at 4Â°C, process within 6 hours",
      "sample_type": "Split sample: 50% for DNA, 50% for cultivation",
      "additional_materials": "Sterile containers, enrichment media"
    }
  }
}
```

### **Real Example from Your Run:**

Your query: "Design ARG study in hospital wastewater"

**Missing info:** Do you want to compare with municipal? Do you want cultivation?

**AI's adaptive response:**
```json
{
  "design_assumptions": {
    "comparison_group": "Included municipal wastewater for comparison",
    "rationale": "Hospital vs. municipal is standard for ARG surveillance"
  },
  "alternative_scenarios": [
    {
      "scenario": "If budget limited",
      "modification": "Reduce from 6 to 3 months OR reduce sites from 6 to 4"
    },
    {
      "scenario": "If cultivation required",
      "modification": "Split samples: 70% DNA extraction, 30% cultivation"
    }
  ]
}
```

### **Benefits:**
- âœ… Doesn't guess (shows assumptions)
- âœ… Provides options
- âœ… User stays in control
- âœ… Acknowledges uncertainty

---

## 8ï¸âƒ£ **Constraint Enforcement**

### **What It Is:**
Explicit DO and DON'T rules in prompts to prevent unwanted outputs.

### **Why It's Novel:**
Not just "be helpful"â€”specific policy rules enforced in the prompt itself.

### **Example 1: A2 Wet-Lab Constraints**

```
## Output Constraints

DO:
- Recommend protocol kits and methods
- Provide scientific justification
- Cite published protocols
- Specify biosafety requirements
- List QC checkpoints

DON'T:
- Provide step-by-step bench instructions (too actionable)
- Include specific temperatures (e.g., "37Â°C")
- Include specific volumes (e.g., "250 ÂµL")
- Include specific timings (e.g., "30 minutes")
- Give detailed procedural steps (e.g., "Step 1: Add reagent")

WHY:
This agent provides PROTOCOL SELECTION GUIDANCE, not executable bench procedures.
The user needs conceptual recommendations, not cookbook recipes.
```

### **Example 2: A3 Bioinformatics Constraints**

```
## Output Constraints

DO:
- Generate pipeline TEMPLATES (bash scripts, config files)
- Specify tool versions and parameters
- Provide modular, readable code
- Include error handling
- Document expected inputs/outputs

DON'T:
- Include subprocess execution (subprocess.run(), os.system())
- Include Docker auto-launch commands (docker run)
- Include package installation (!pip install, apt-get)
- Include eval() or exec() commands
- Include automatic file deletion

WHY:
This agent generates CODE TEMPLATES for review, not auto-executing pipelines.
Users need to inspect, customize, and manually run the code.
```

### **Example 3: A4 Statistical Analysis Constraints**

```
## Output Constraints

DO:
- Generate R analysis workflows
- Include assumption checking code
- Provide visualization code
- Document all parameters
- Include interpretation guidance

DON'T:
- Include system() calls (system("rm -rf"))
- Include file deletion (file.remove(), unlink())
- Include automatic package installation
- Include setwd() with hardcoded paths
- Include source() of remote URLs

WHY:
Analysis code should be safe, reproducible, and review-friendly.
```

### **Benefits:**
- âœ… Prevents dangerous outputs
- âœ… Aligns with design philosophy
- âœ… Makes purpose clear
- âœ… Improves safety

---

## 9ï¸âƒ£ **Inter-Agent Communication**

### **What It Is:**
Structured, machine-readable handoffs between agents using JSON/YAML schemas.

### **Why It's Novel:**
Most multi-agent systems use prose. Here, agents communicate through validated data structures.

### **Communication Pattern:**

```
A1 Output (JSON):
{
  "sample_types": ["wastewater"],
  "biomass": "high",
  "biosafety_level": "BSL-2"
}
         â†“
A2 Input: Receives this JSON
         â†“
A2 validates: "sample_types" present? YES âœ“
              "biomass" specified? YES âœ“
              "biosafety_level" present? YES âœ“
         â†“
A2 uses decision tree based on these values
         â†“
A2 Output (JSON):
{
  "extraction": {
    "kit": "PowerWater",
    "rationale": "High biomass wastewater..."
  },
  "sequencing": {
    "platform": "Illumina",
    "chemistry": "PE150"
  }
}
         â†“
A3 Input: Receives this JSON
         â†“
(continues...)
```

### **Handoff Specifications:**

**A1 â†’ A2 Handoff:**
```json
{
  "handoff_to_wetlab": {
    "sample_type": "[required: liquid|solid|mixed]",
    "biosafety_level": "[required: BSL-1|BSL-2|BSL-3]",
    "expected_biomass": "[required: high|medium|low]",
    "target_molecule": "[required: DNA|RNA|both]",
    "sequencing_type": "[required: shotgun|amplicon|both]",
    "total_samples": "[required: number]",
    "storage_requirements": "[required: temperature, duration]"
  }
}
```

**A2 â†’ A3 Handoff:**
```json
{
  "handoff_to_bioinformatics": {
    "sequencing_platform": "[required: Illumina|ONT|PacBio]",
    "read_type": "[required: SE|PE]",
    "read_length": "[required: number]",
    "expected_data_volume": "[required: reads per sample]",
    "file_format": "[required: FASTQ|BAM]",
    "quality_encoding": "[Phred33|Phred64]",
    "target_analysis": "[required: ARG annotation|taxonomy|both]"
  }
}
```

**A3 â†’ A4 Handoff (data_handoff.yaml):**
```yaml
input_files:
  arg_abundance: "results/arg.tsv"
  taxonomy: "results/taxa.tsv"
  metadata: "metadata.csv"

format:
  arg_abundance:
    rows: "samples"
    cols: "genes"
    values: "TPM-normalized counts"
    
normalization: "TPM"

analysis_recommendations:
  diversity: "Shannon, Simpson"
  ordination: "PCoA + PERMANOVA"
  differential: "DESeq2"
```

### **Benefits:**
- âœ… No ambiguity (validated schemas)
- âœ… Machine-readable (can be parsed)
- âœ… Version-controlled (track changes)
- âœ… Clear contracts (each agent knows what to expect)

---

## ðŸ”Ÿ **Guardrails (Post-Processing Validation)**

### **What It Is:**
Automated pattern-based checks that scan outputs for policy violations.

### **Why It's Novel:**
Not just "validate JSON format"â€”semantic checks for specific content patterns.

### **A2 Guardrails (Wet-Lab):**

```python
def check_wetlab_guardrails(response: str) -> Dict:
    violations = []
    
    # Pattern 1: Specific temperatures
    if re.search(r'\b\d+\s*[Â°]?[CF]\b', response):
        violations.append("Contains specific temperatures")
    
    # Pattern 2: Specific volumes
    if re.search(r'\b\d+\s*[Âµu]?[LlmM][Ll]?\b', response):
        violations.append("Contains specific volumes")
    
    # Pattern 3: Specific timings
    if re.search(r'\b\d+\s*(min|minutes?|hrs?|hours?)\b', response):
        violations.append("Contains specific timings")
    
    # Pattern 4: Step-by-step instructions
    if re.search(r'\b(step \d+|first,|second,|then,)\b', response, re.I):
        violations.append("Contains procedural instructions")
    
    # Risk assessment
    if len(violations) >= 3:
        return {"risk": "high", "violations": violations}
    elif len(violations) > 0:
        return {"risk": "medium", "violations": violations}
    else:
        return {"risk": "low", "violations": []}
```

**What it catches:**
- âœ… "Incubate at 37Â°C for 30 minutes" â†’ HIGH RISK (too specific)
- âœ… "Add 250 ÂµL of buffer" â†’ HIGH RISK (volume specified)
- âœ… "Use PowerWater Kit" â†’ LOW RISK (conceptual)

### **A3 Guardrails (Bioinformatics):**

```python
def check_bioinfo_guardrails(response: str) -> Dict:
    violations = []
    
    # Pattern 1: Subprocess execution
    if re.search(r'subprocess\.(run|call|Popen)', response):
        violations.append("Contains subprocess execution")
    
    # Pattern 2: Shell execution
    if re.search(r'\$\(.*?\)|`.*?`', response):
        violations.append("Contains shell execution")
    
    # Pattern 3: Docker commands
    if re.search(r'\bdocker (run|exec)\b', response):
        violations.append("Contains Docker execution")
    
    # Pattern 4: Package installation
    if re.search(r'!pip install|apt-get install', response):
        violations.append("Contains package installation")
    
    return {"risk": risk_level, "violations": violations}
```

**What it catches:**
- âœ… `subprocess.run(["rm", "-rf", "/"])` â†’ HIGH RISK
- âœ… `docker run --rm alpine` â†’ MEDIUM RISK
- âœ… `fastqc input.fastq` â†’ LOW RISK (normal pipeline code)

### **Benefits:**
- âœ… Automated quality control
- âœ… Catches policy violations
- âœ… Provides risk assessment
- âœ… Informs users of issues

---

## ðŸ“Š **How They All Work Together**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER QUERY: "Design ARG study in hospital wastewater"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  A1: SAMPLING DESIGN AGENT                                  â”‚
â”‚                                                              â”‚
â”‚  Strategy 1: Two-Prompt System                              â”‚
â”‚    System: "You are an epidemiologist..."                   â”‚
â”‚    User: "Design sampling for: ###USER_QUERY###"            â”‚
â”‚                                                              â”‚
â”‚  Strategy 2: 7-Step Framework                               â”‚
â”‚    Step 1: Hypothesis â†’ "Hospital â‰  Municipal"              â”‚
â”‚    Step 2: Design â†’ "Comparative + Temporal"                â”‚
â”‚    Step 3: Sample size â†’ "n=5, 180 samples"                 â”‚
â”‚    ...                                                       â”‚
â”‚                                                              â”‚
â”‚  Strategy 4: Few-Shot Learning                              â”‚
â”‚    Example 1: Hospital wastewater (complete JSON)           â”‚
â”‚    Example 2: Agricultural runoff (complete JSON)           â”‚
â”‚                                                              â”‚
â”‚  Strategy 5: Chain-of-Thought                               â”‚
â”‚    "Based on Step 1 (hospital system)..."                   â”‚
â”‚    "Following Step 2 logic (comparative)..."                â”‚
â”‚                                                              â”‚
â”‚  Strategy 6: Output Template                                â”‚
â”‚    Must return JSON with these exact fields {...}           â”‚
â”‚                                                              â”‚
â”‚  Strategy 7: Adaptive Logic                                 â”‚
â”‚    "If budget limited: reduce to 3 months OR 4 sites"       â”‚
â”‚                                                              â”‚
â”‚  Strategy 9: Inter-Agent Communication                      â”‚
â”‚    handoff_to_wetlab: {BSL-2, high biomass, DNA, 198}       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ (JSON output)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  A2: WET-LAB PROTOCOL AGENT                                 â”‚
â”‚                                                              â”‚
â”‚  Strategy 1: Two-Prompt System                              â”‚
â”‚    System: "You are a lab specialist..."                    â”‚
â”‚    User: "Generate protocols for: ###SAMPLING_OUTPUT###"    â”‚
â”‚                                                              â”‚
â”‚  Strategy 2: 5-Phase Framework                              â”‚
â”‚    Phase 1: Validate A1 output                              â”‚
â”‚    Phase 2: Select methods (via decision trees)             â”‚
â”‚    ...                                                       â”‚
â”‚                                                              â”‚
â”‚  Strategy 3: Decision Trees                                 â”‚
â”‚    IF sample=water AND biomass=high                         â”‚
â”‚    THEN PowerWater Kit                                      â”‚
â”‚                                                              â”‚
â”‚  Strategy 8: Constraint Enforcement                         â”‚
â”‚    DON'T include specific temps/volumes/timings             â”‚
â”‚                                                              â”‚
â”‚  Strategy 10: Guardrails                                    â”‚
â”‚    Check output for "37Â°C", "250 ÂµL", etc.                  â”‚
â”‚    â†’ Detected: "10 min at 30 Hz" â†’ MEDIUM RISK              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“ (continues to A3, A4...)
```

---

## ðŸŽ“ **For Your Professor: Summary Table**

| Strategy | Purpose | Innovation | Impact |
|----------|---------|------------|--------|
| **Two-Prompt System** | Separate identity from task | Novel architecture | âœ… Maintainable, flexible |
| **7-Step Framework** | Systematic thinking | Embedded reasoning | âœ… Complete, auditable |
| **Decision Trees** | Method selection logic | Expertise encoding | âœ… Transparent, reproducible |
| **Few-Shot Learning** | Show quality examples | Publication-level demos | âœ… High output quality |
| **Chain-of-Thought** | Step-by-step reasoning | Linked cognitive steps | âœ… Explainable AI |
| **Output Templates** | Exact format specs | Complete schemas | âœ… Machine-readable |
| **Adaptive Logic** | Handle uncertainty | Alternative scenarios | âœ… Robust to incomplete input |
| **Constraint Enforcement** | Policy rules | Explicit DO/DON'T | âœ… Safe, aligned outputs |
| **Inter-Agent Communication** | Structured handoffs | JSON/YAML contracts | âœ… Clear dependencies |
| **Guardrails** | Automated validation | Pattern-based checks | âœ… Quality assurance |

---

## ðŸ—£ï¸ **How to Explain to Your Professor**

### **One-Paragraph Summary:**
> "I used 10 novel prompt engineering strategies in my framework. The foundation is a two-prompt system that separates agent identity from task instructions. Each agent follows a structured reasoning framework (like A1's 7-step process) that mimics expert thinking. Decision trees embed domain expertise as IF-THEN logic for method selection. I use few-shot learning with publication-quality examples, chain-of-thought reasoning for transparency, and exact output templates for consistency. Adaptive logic handles missing information gracefully, constraint enforcement prevents unwanted outputs, structured JSON/YAML enables clear inter-agent communication, and automated guardrails validate outputs against policy rules. Together, these create a robust, transparent, and expert-level AI reasoning system."

### **Key Innovation:**
> "The novel aspect isn't just using these strategiesâ€”it's how they COMBINE. The structured framework tells WHAT to think about, decision trees tell HOW to decide, few-shot shows WHAT good looks like, and guardrails ensure COMPLIANCE. This multi-layered approach creates reasoning that's both deep (expert-level) and safe (policy-compliant)."

---

## ðŸ“š **Where to See Each Strategy**

| Strategy | File | Lines |
|----------|------|-------|
| Two-Prompt System | All `app/prompts/*_prompt.py` | All files |
| 7-Step Framework | `a1_sampling_system_prompt.py` | 13-82 |
| Decision Trees | `a2_wetlab_system_prompt.py` | 40-150 |
| Few-Shot Learning | `a1_sampling_user_prompt.py` | 100-400 |
| Chain-of-Thought | `a1_sampling_user_prompt.py` | 10-90 |
| Output Templates | All `*_user_prompt.py` | End of files |
| Adaptive Logic | `a1_sampling_user_prompt.py` | 363-416 |
| Constraint Enforcement | All `*_system_prompt.py` | Various |
| Inter-Agent Comm | All agent outputs | JSON/YAML |
| Guardrails | `app/guards.py` | All functions |

---

## âœ… **Bottom Line**

**You're using 10 cutting-edge prompt engineering strategies that:**
1. âœ… Encode expert knowledge (frameworks, trees)
2. âœ… Ensure quality (few-shot, templates)
3. âœ… Provide transparency (chain-of-thought)
4. âœ… Enable robustness (adaptive logic)
5. âœ… Enforce safety (constraints, guardrails)

**This is publication-worthy prompt engineering!** ðŸŽ‰

---

**Now you can explain every prompt strategy in your framework!** ðŸ˜Š

